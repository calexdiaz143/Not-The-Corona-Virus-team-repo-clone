{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_ratio(y, predictions):\n",
    "    total_correct = sum(predictions == y)\n",
    "    return (total_correct/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "df = pd.read_csv('data/Challenge1_Training_Scenarios.csv')\n",
    "df.set_index('scenario_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab X and y values and split 80/20 train/test\n",
    "X = df['scenario']\n",
    "y = df['danger_level']\n",
    "\n",
    "train_X = X[:404]\n",
    "train_y = y[:404]\n",
    "\n",
    "test_X = X[404:]\n",
    "test_y = y[404:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bows\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#stopwords_adjusted = list(stopwords.words('english'))\n",
    "vect = CountVectorizer(stop_words=stopwords.words('english'), ngram_range=(1,3))\n",
    "train_counts = vect.fit_transform(train_X)\n",
    "test_counts = vect.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_mnb = MultinomialNB()\n",
    "clf_mnb.fit(train_counts, train_y)\n",
    "\n",
    "pred = clf_mnb.predict(test_counts)\n",
    "print(accuracy_ratio(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(train_counts, train_y)\n",
    "\n",
    "pred = np.rint(clf_lr.predict(test_counts))\n",
    "print(accuracy_ratio(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_kn = KNeighborsClassifier()\n",
    "clf_kn.fit(train_counts, train_y)\n",
    "\n",
    "pred = clf_kn.predict(test_counts)\n",
    "print(accuracy_ratio(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svc = SVC()\n",
    "clf_svc.fit(train_counts, train_y)\n",
    "\n",
    "pred = clf_svc.predict(test_counts)\n",
    "print(accuracy_ratio(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec to embed inside/outside\n",
    "# linear regression matrix to get confidence levels of specific words\n",
    "# stemming\n",
    "# lemmatization\n",
    "# stopwords remove in/out etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import word embedding packages\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "import string\n",
    "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab embeddings for valued words and format\n",
    "valued_negative_words = ['inside', 'crowd', 'touch', 'alcohol', 'kids', 'travel', 'airplane', 'elderly', 'illness', 'group', 'sick']\n",
    "valued_positive_words = ['outside', 'alone', 'home', 'sanitation']\n",
    "\n",
    "for i, word in enumerate(valued_negative_words):\n",
    "    valued_negative_words[i] = glove_vectors[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize each entry then turn each word into vector\n",
    "train_embedded_X = train_X.copy()\n",
    "for i, entry in enumerate(train_embedded_X, start=1):\n",
    "    train_embedded_X[i] = word_tokenize(train_embedded_X[i])\n",
    "    train_embedded_X[i] = list(filter(lambda token: token not in string.punctuation, train_embedded_X[i]))\n",
    "    for j, word in enumerate(train_embedded_X[i]):\n",
    "        if train_embedded_X[i][j] in glove_vectors:\n",
    "            train_embedded_X[i][j] = glove_vectors[train_embedded_X[i][j]]\n",
    "        else:\n",
    "            train_embedded_X[i][j] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedded_X = test_X.copy()\n",
    "for i, entry in enumerate(test_embedded_X, start=405):\n",
    "    test_embedded_X[i] = word_tokenize(test_embedded_X[i])\n",
    "    test_embedded_X[i] = list(filter(lambda token: token not in string.punctuation, test_embedded_X[i]))\n",
    "    for j, word in enumerate(test_embedded_X[i]):\n",
    "        if test_embedded_X[i][j] in glove_vectors:\n",
    "            test_embedded_X[i][j] = glove_vectors[test_embedded_X[i][j]]\n",
    "        else:\n",
    "            test_embedded_X[i][j] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each entry\n",
    "for i, entry in enumerate(train_embedded_X, start=1):\n",
    "    # track total distance\n",
    "    total_distance = 0\n",
    "    # for each word\n",
    "    for j, word in enumerate(train_embedded_X[i]):\n",
    "        # if there was an embedding for this word\n",
    "        if word is not None:\n",
    "            closest_distance = float('inf')\n",
    "            # find closest distance to a valued word\n",
    "            for k, valued_word in enumerate(valued_negative_words):\n",
    "                current_distance = np.sum(np.square(valued_word - word))\n",
    "                if current_distance < closest_distance:\n",
    "                    closest_distance = current_distance\n",
    "            total_distance += closest_distance\n",
    "\n",
    "    # average total distance based on number of words?\n",
    "    # replace entry\n",
    "    train_embedded_X[i] = total_distance/len(entry)\n",
    "\n",
    "# shape this data into something useable for ml stuff\n",
    "train_embedded_X = train_embedded_X.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing for test set\n",
    "\n",
    "# for each entry\n",
    "for i, entry in enumerate(test_embedded_X, start=405):\n",
    "    # track total distance\n",
    "    total_distance = 0\n",
    "    # for each word\n",
    "    for j, word in enumerate(test_embedded_X[i]):\n",
    "        # if there was an embedding for this word\n",
    "        if word is not None:\n",
    "            closest_distance = float('inf')\n",
    "            # find closest distance to a valued word\n",
    "            for k, valued_word in enumerate(valued_negative_words):\n",
    "                current_distance = np.sum(np.square(valued_word - word))\n",
    "                if current_distance < closest_distance:\n",
    "                    closest_distance = current_distance\n",
    "            total_distance += closest_distance\n",
    "\n",
    "    # average total distance based on number of words?\n",
    "    # replace entry\n",
    "    test_embedded_X[i] = total_distance/len(entry)\n",
    "\n",
    "# shape this data into something useable for ml stuff\n",
    "test_embedded_X = test_embedded_X.to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19\n"
     ]
    }
   ],
   "source": [
    "# simple naive bayes on embeddings\n",
    "embedded_clf_mnb = MultinomialNB()\n",
    "embedded_clf_mnb.fit(train_embedded_X, train_y)\n",
    "pred = embedded_clf_mnb.predict(test_embedded_X)\n",
    "print(accuracy_ratio(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16\n"
     ]
    }
   ],
   "source": [
    "# simple lr on embeddings\n",
    "embedded_clf_lr = LogisticRegression()\n",
    "embedded_clf_lr.fit(train_embedded_X, train_y)\n",
    "pred = embedded_clf_lr.predict(test_embedded_X)\n",
    "print(accuracy_ratio(test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next steps would be finding maybe better metrics than total distance averaged, or combining this output with n-gram stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
