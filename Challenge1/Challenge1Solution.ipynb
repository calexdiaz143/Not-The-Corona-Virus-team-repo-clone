{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# import word embedding packages\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "import string\n",
    "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_ratio(y, predictions):\n",
    "    zipped = zip(y, predictions)\n",
    "    total_points = 0\n",
    "    for curr in zipped:\n",
    "        if curr[0] == curr[1]:\n",
    "            total_points += 2\n",
    "        elif curr[0] == curr[1]+1 or curr[0] == curr[1]-1:\n",
    "            total_points += 1\n",
    "        else:\n",
    "            total_points += 0\n",
    "\n",
    "    return (total_points/(len(y)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_predictions(X, y, pred):\n",
    "    visualize = pd.DataFrame(list(zip(list(X), y, list(pred))))\n",
    "    visualize['diff'] = list(np.subtract(y, pred))\n",
    "    visualize = visualize.sort_values(by = 'diff')\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    print(visualize.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data loading\n",
    "df_train = pd.read_csv('data/Challenge1_Training_Scenarios.csv')\n",
    "df_train.set_index('scenario_id', inplace=True)\n",
    "\n",
    "df_test = pd.read_csv('data/Challenge1_Test_Scenarios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# development, split training set\n",
    "X = df['scenario']\n",
    "y = df['danger_level']\n",
    "X, y = shuffle(X, y)\n",
    "train_X = list(X[:404])\n",
    "train_y = list(y[:404])\n",
    "test_X = list(X[404:])\n",
    "test_y = list(y[404:])\n",
    "\n",
    "# creating submission, full training set\n",
    "#train_X = list(df_train['scenario'])\n",
    "#train_y = list(df_train['danger_level'])\n",
    "\n",
    "#test_X = list(df_test['scenario'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bows\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "vect = TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1,3))\n",
    "train_counts = vect.fit_transform(train_X)\n",
    "test_counts = vect.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "bow_mnb = MultinomialNB()\n",
    "bow_mnb.fit(train_counts, train_y)\n",
    "\n",
    "pred_bow_mnb = bow_mnb.predict(test_counts)\n",
    "#print(accuracy_ratio(test_y, pred_bow_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "bow_lr = LogisticRegression()\n",
    "bow_lr.fit(train_counts, train_y)\n",
    "\n",
    "pred_bow_lr = np.rint(bow_lr.predict(test_counts))\n",
    "#print(accuracy_ratio(test_y, pred_bow_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bow_kn = KNeighborsClassifier()\n",
    "bow_kn.fit(train_counts, train_y)\n",
    "\n",
    "pred_bow_kn = bow_kn.predict(test_counts)\n",
    "#print(accuracy_ratio(test_y, pred_bow_kn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "bow_svc = SVC()\n",
    "bow_svc.fit(train_counts, train_y)\n",
    "\n",
    "pred_bow_svc = bow_svc.predict(test_counts)\n",
    "#print(accuracy_ratio(test_y, pred_bow_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view_predictions(test_X, test_y, pred_bow_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_remove_punctuation(input):\n",
    "    input = input.lower()\n",
    "    input = word_tokenize(input)\n",
    "    input = list(filter(lambda token: token not in string.punctuation, input))\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab embeddings for valued words and format\n",
    "valued_negative_words = ['elderly', 'mask', 'social', 'coronavirus', 'home', 'work', 'outside']\n",
    "\n",
    "for i, word in enumerate(valued_negative_words):\n",
    "    valued_negative_words[i] = glove_vectors[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to embeddings for each entry\n",
    "train_embedded_X = train_X.copy()\n",
    "for i, entry in enumerate(train_embedded_X):\n",
    "    train_embedded_X[i] = tokenize_remove_punctuation(train_embedded_X[i])\n",
    "\n",
    "    if 'covid-19' in train_embedded_X[i]:\n",
    "        train_embedded_X[i][train_embedded_X[i].index('covid-19')] = 'coronavirus'\n",
    "    if 'covid' in train_embedded_X[i]:\n",
    "        train_embedded_X[i][train_embedded_X[i].index('covid')] = 'coronavirus'\n",
    "\n",
    "    for j, word in enumerate(train_embedded_X[i]):\n",
    "        if train_embedded_X[i][j] in glove_vectors:\n",
    "            train_embedded_X[i][j] = glove_vectors[train_embedded_X[i][j]]\n",
    "        else:\n",
    "            train_embedded_X[i][j] = None\n",
    "\n",
    "            \n",
    "test_embedded_X = test_X.copy()\n",
    "for i, entry in enumerate(test_embedded_X):\n",
    "    test_embedded_X[i] = tokenize_remove_punctuation(test_embedded_X[i])\n",
    "    \n",
    "    if 'covid-19' in test_embedded_X[i]:\n",
    "        test_embedded_X[i][test_embedded_X[i].index('covid-19')] = 'coronavirus'\n",
    "    if 'covid' in test_embedded_X[i]:\n",
    "        test_embedded_X[i][test_embedded_X[i].index('covid')] = 'coronavirus'\n",
    "    \n",
    "    for j, word in enumerate(test_embedded_X[i]):\n",
    "        if test_embedded_X[i][j] in glove_vectors:\n",
    "            test_embedded_X[i][j] = glove_vectors[test_embedded_X[i][j]]\n",
    "        else:\n",
    "            test_embedded_X[i][j] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector of closest distances to each valued word approach\n",
    "for i, entry in enumerate(train_embedded_X):\n",
    "    curr_min_distance_vec = np.full(len(valued_negative_words), float('inf'))\n",
    "\n",
    "    # for each word\n",
    "    for j, word in enumerate(train_embedded_X[i]):\n",
    "        if word is not None:\n",
    "            # loop through valued words\n",
    "            for k, valued_word in enumerate(valued_negative_words):\n",
    "                curr_distance = np.sum(np.square(valued_word - word))\n",
    "                if curr_distance < curr_min_distance_vec[k]:\n",
    "                    curr_min_distance_vec[k] = curr_distance\n",
    "    train_embedded_X[i] = curr_min_distance_vec.copy()\n",
    "\n",
    "train_embedded_X = list(train_embedded_X)\n",
    "\n",
    "for i, entry in enumerate(test_embedded_X):\n",
    "    curr_min_distance_vec = np.full(len(valued_negative_words), float('inf'))\n",
    "\n",
    "    # for each word\n",
    "    for j, word in enumerate(test_embedded_X[i]):\n",
    "        if word is not None:\n",
    "            # loop through valued words\n",
    "            for k, valued_word in enumerate(valued_negative_words):\n",
    "                curr_distance = np.sum(np.square(valued_word - word))\n",
    "                if curr_distance < curr_min_distance_vec[k]:\n",
    "                    curr_min_distance_vec[k] = curr_distance\n",
    "    test_embedded_X[i] = curr_min_distance_vec.copy()\n",
    "\n",
    "test_embedded_X = list(test_embedded_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_mnb = MultinomialNB()\n",
    "embedded_mnb.fit(train_embedded_X, train_y)\n",
    "pred_embedded_mnb = embedded_mnb.predict(test_embedded_X)\n",
    "#print(accuracy_ratio(test_y, pred_embedded_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "embedded_lr = LinearRegression()\n",
    "embedded_lr.fit(train_embedded_X, train_y)\n",
    "pred_embedded_lr = np.rint(embedded_lr.predict(test_embedded_X))\n",
    "#print(accuracy_ratio(test_y, pred_embedded_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_svc = SVC()\n",
    "embedded_svc.fit(train_embedded_X, train_y)\n",
    "pred_embedded_svc = embedded_svc.predict(test_embedded_X)\n",
    "#print(accuracy_ratio(test_y, pred_embedded_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensembling predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_majority(prediction_list, index):\n",
    "    prediction = [pred[index] for pred in prediction_list]\n",
    "    majority = Counter(prediction).most_common()\n",
    "    return majority[0][0]\n",
    "\n",
    "def predict_ensemble(prediction_list):\n",
    "    ensemble_predictions = []\n",
    "    for i, curr_pred in enumerate(prediction_list[0]):\n",
    "        ensemble_predictions.append(get_majority(prediction_list, i))\n",
    "    return ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = [pred_bow_mnb, pred_bow_lr, pred_bow_kn, pred_bow_svc, pred_embedded_mnb, pred_embedded_lr, pred_embedded_svc]\n",
    "ensemble_predictions = predict_ensemble(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output code if creating submission\n",
    "# output = pd.DataFrame(zip(list(df_test['scenario_id']), ensemble_predictions), columns=['scenario_id','danger_level'])\n",
    "# output.to_csv('submission/Challenge1_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
